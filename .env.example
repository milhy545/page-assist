# Page Assist - Environment Variables Example
# Copy this file to .env and fill in your API keys

# ====================================
# AI Provider API Keys
# ====================================

# Mercury (Inception Labs) - Ultra-fast diffusion LLM
# Get your key at: https://mercuryai.com
MERCURY_API_KEY=your_mercury_api_key_here

# Anthropic Claude - Superior reasoning, 200K context
# Get your key at: https://console.anthropic.com
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI - GPT-4, GPT-3.5, DALL-E 3
# Get your key at: https://platform.openai.com
OPENAI_API_KEY=your_openai_api_key_here

# Groq - Ultra-fast inference (800 tokens/sec)
# Get your key at: https://console.groq.com
GROQ_API_KEY=your_groq_api_key_here

# Mistral AI
# Get your key at: https://console.mistral.ai
MISTRAL_API_KEY=your_mistral_api_key_here

# Together AI
# Get your key at: https://api.together.xyz
TOGETHER_API_KEY=your_together_api_key_here

# Perplexity AI
# Get your key at: https://www.perplexity.ai/settings/api
PERPLEXITY_API_KEY=your_perplexity_api_key_here

# DeepSeek
# Get your key at: https://platform.deepseek.com
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Fireworks AI
# Get your key at: https://fireworks.ai/api-keys
FIREWORKS_API_KEY=your_fireworks_api_key_here

# ====================================
# Image Generation
# ====================================

# Replicate - For Stable Diffusion and Flux
# Get your key at: https://replicate.com/account/api-tokens
REPLICATE_API_KEY=your_replicate_api_key_here

# ====================================
# Other Services
# ====================================

# ElevenLabs - Text to Speech
# Get your key at: https://elevenlabs.io/app/settings
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here

# ====================================
# Application Settings
# ====================================

# Default AI model
DEFAULT_MODEL=mercury-coder-mini

# Enable debug mode (true/false)
DEBUG=false

# Enable performance monitoring (true/false)
ENABLE_MONITORING=true

# API rate limiting (requests per minute)
RATE_LIMIT=60

# Maximum tokens for responses
MAX_TOKENS=2048

# Temperature (0-1)
TEMPERATURE=0.7

# ====================================
# Dashboard Settings
# ====================================

# Dashboard port
VITE_PORT=3000

# API endpoint (if using separate backend)
VITE_API_URL=http://localhost:3001

# Enable analytics (true/false)
VITE_ENABLE_ANALYTICS=false

# ====================================
# Security
# ====================================

# Session secret (generate with: openssl rand -base64 32)
SESSION_SECRET=your_session_secret_here

# Allowed origins for CORS (comma-separated)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173

# ====================================
# Optional: Custom Endpoints
# ====================================

# Custom OpenAI-compatible endpoint
# CUSTOM_OPENAI_ENDPOINT=https://your-custom-endpoint.com/v1

# Custom model name for custom endpoint
# CUSTOM_MODEL_NAME=your-model-name

# ====================================
# Notes
# ====================================

# 1. Never commit your .env file to git!
# 2. Keep your API keys secure
# 3. Most providers offer free tiers
# 4. You don't need all keys - only for providers you want to use
# 5. See UNIFIED_DASHBOARD.md for more details
